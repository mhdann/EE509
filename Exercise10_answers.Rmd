---
title: "Lab 10 - Hierarchical Bayes"
author: "Michael Dann"
date: "November 17th, 2014"
output: html_document
---

The objective of this lab is to begin to explore hierarchical models.  We will focus on the most common class of hierarchical models, which are linear mixed models.  Mixed models refer to models that include both hierarchical “random” effects and non-hierarchical “fixed” effects.  Everything that we apply below to linear models can also be applied to generalized linear models (e.g. logistic and poisson regression) and thus falls within the class of models referred to as GLMM (generalized linear mixed models) for which all of our traditional non-hierarchical linear and GLM exist as a special case.  While we have focused on random effects from the Bayesian perspective, special cases on GLMM can also be solved from the Maximum Likelihood perspective. However, it is much harder to generalize Maximum Likelihood random effects models if you need to relax additional assumptions or if you have a nonlinear model.

## R2WinBUGS

The other thing that will be introduced in this lab is the technique of calling WinBUGS directly from R.  While I would like you to **TRY** this approach at least once for the example below, if you then prefer to work with the WinBUGS graphical user interface you are welcome to do so for the rest of the lab.  The advantages of calling BUGS from R (or calling JAGS for Mac and Linux users) are that you don't have to work as hard to get your data into BUGS, that you are freed of continually having to hit the same sequence of buttons every time you want to run the model, and that you get the full MCMC chain back, which allows you to do further computation with the output.  The disadvantages are that you get less information back when debugging (though there are ways around this), you loose the “click of a button” graphs, and you loose the instant feedback on the progress of the MCMC sampler.

To be able to call WinBUGS from R we need to load up the appropriate libraries

```{r}
library(R2WinBUGS)
library(BRugs)  ## only required if using OpenBUGS
```

Next, lets consider the simple BUGS model for fitting the mean and precision of a normal distribution. To be able pass this model to BUGS we're going to define it as a string within R.

```{r, echo=F}
FitNorm <- function(){
  mu ~ dnorm(0,0.001)
  prec ~ dgamma(0.1,0.1)
	for(i in 1:n){
	  x[i] ~ dnorm(mu,prec)
	}  
}
write.model(model = FitNorm, con="FitNorm.txt")
```
  
The next step is to then to send the model to BUGS/JAGS using the “openbugs” or "jags.model" function.   This function call is complicated so I recommend typing ?openbugs and/or ?jags.model at the command line to see all the options and arguments.

```{r}
x = rnorm(10,3,0.5)               ## pseudo-data
data = list(x=x,n=10)
init = NULL

b1 = openbugs(data=data,  ## data passed to the model
  init=init,		## initial conditions, NULL is equivalent to “gen inits”
	model.file="FitNorm.txt",  ## file name of our BUGS file 
	n.chains=3,		## number of MCMC chains
	n.iter=2000,		## length of each chain
	n.burnin=100,		## burn in to exclude
	n.thin = 2,		## thin
	parameters.to.save=c("mu","prec")  ## parameters we want to track
)
```

Data is passed to this function as a list that is structured the same way as we were outputting data previously.  If you want to specify the initial conditions there are two options.  First they could be specified in a list of lists.  For example

```{r}
init.cond1 <- list()
init.cond1[[1]] = list(mu=0,prec=1)
init.cond1[[2]] = list(mu=5,prec=2)
init.cond1[[3]] = list(mu=10,prec=0.5)
```

Alternatively, the initial conditions can be specified by a function that returns a list.  This function can either be deterministic or generate initial conditions randomly

```{r}
init.cond2 <- function(){
  ## starts each chain from the same initial conditions
	list(mu=5,prec=2)
}
init.cond3  <- function(){
  ## generates random initial conditions
	list(mu=rnorm(1,5,2),prec=runif(1,0.5,2.0))
}
```

The data object returned by *openbugs* is complicated and has many components.  I recommend using names(b1) to see what is returned and then to take a look at each of the components.  The “sims” components (matrix, list, and array) are the raw MCMC chains stored in three different formats.  Since these parts are large I recommend against looking at them directly.  Probably the most useful format for the raw MCMC is sims.array which is a 3D array that is structured by (sample, chain,parameter).  The BUGS data object can be converted to a CODA object using the function as.mcmc.list, and then you can use all the functions from Labs 6 and 7 to produce your standard diagnostics. By constrast, JAGS alreay returns the MCMC sample formated as an mcmc.list

```{r}
## diagnostics of the MCMC
bmcmc <- as.mcmc.list(b1)  ## convert to MCMC object

plot(bmcmc)			## mcmc history and density plot
autocorr.plot(bmcmc)		## autocorrelation
cumuplot(bmcmc)		## quantile plot
gelman.plot(bmcmc)		## GRB statistic
summary(bmcmc)		## summary table
```

You can also calculate quantiles explicitly, for example for use in plotting model CI and PI.
 
```{r}
mu = as.data.frame(as.matrix(bmcmc))$mu
quantile(mu,c(0.025,0.5,0.975))
```


## Case Study: Mosquito population size

For this lab we will look at data on mosquito abundance.  The data file “Mosquito.csv” contains ten years worth of data for each of 5 replicate traps (Reminder: the function read.csv can be used to read comma-separated text files).   We will begin with the simplest possible model to explain this data and incrementally add complexity.

**Lab Report Task 1:** 

1.  Plot mosquito abundance as a function of time in a way that distinguishes the reps (e.g. with lines, colors, or symbols)

```{r}
library(reshape)
library(ggplot2)
library(scales)
df <- read.csv("data/Mosquito.csv", header=T)
long <- melt(df, "time")
p <- ggplot(long, aes(time,value)) +
  geom_line(aes(color=variable)) + theme_bw() +
  labs(x="Year", y = "Population") +
  scale_x_continuous(breaks=pretty_breaks()) +
  scale_color_brewer(type = "seq", palette = 3)
p
```

2.	Fit the overall mean and standard deviation, reporting summary statistics for both (hint: you can use the BUGS code above, but remember that your “x” is a matrix of year-by-rep and thus you will need to loop over both year and rep rather than just looping 'i in 1:n')

```{r}
FitNormPanel <- function(){
  mu ~ dnorm(7,0.001)
  prec ~ dgamma(0.01,0.01)
  for(t in 1:nt){
    for(i in 1:nrep){
      x[t,i] ~ dnorm(mu,prec)  
    }        
	}  
}
write.model(model = FitNormPanel, con="FitNormPanel.txt")



# strip the last 5 columns (the reps), by column
data  = list(nt=10, nrep=5, x=structure(.Data = as.vector(unlist(df[,2:6])),.Dim=c(10,5)))

init = NULL
b2 = openbugs(data=data,  ## data passed to the model
  init=init,  	## initial conditions, NULL is equivalent to “gen inits”
	model.file="FitNormPanel.txt",  ## file name of our BUGS file 
	n.chains=3,		## number of MCMC chains
	n.iter=2000,		## length of each chain
	n.burnin=100,		## burn in to exclude
	n.thin = 2,		## thin
	parameters.to.save=c("mu","prec")  ## parameters we want to track
)
quants2 <- apply(b2$sims.matrix,2, quantile, c(0.025, 0.5, 0.975))
quants2
```



3.	Add posterior CI and PI to the plot

Hint 1:  When converting the mosquito data to be 'x' you need to shave off the “time” column for this to have the correct dimensions and indexing.
Hint 2: If using R2WinBUGS you will want to name the output BUGS object (e.g. b1 in the above example) something different for each model you construct so that you don't have to re-run the model if you find you need additional information from it later (e.g. DIC, values to use as initial conditions in more complex models, etc.).
```{r}
p  + geom_hline(yintercept=quants2[,1], color="green") + geom_hline(yintercept=quants2[2,1]+1.96*1/sqrt(quants2[2,2]), color="red")+ geom_hline(yintercept=quants2[2,1]-1.96*1/sqrt(quants2[2,2]), color="red")
```
The PI has been taken from the Student's T-distribution about the mean.

## Random time effect

From the graphs in Task 1 it should be apparent that there is systematic year-to-year variability that is unexplained by just a simple mean.  Since at this point we don't know the cause of this variability we can begin by adding a random effect for year.  Adding year effect requires, first, that we add the random effects, alpha.t, to the process model and, second, that we also specify a prior on random effects variance

```{r}
FitNormPanelRandom <-function(){
  mu ~ dnorm(7,0.001)   	## prior mean
  sigma ~ dgamma(0.001,0.001)	## prior residual precision
  tau.t ~ dgamma(0.001,0.001)	## prior year-effect precision
  
  for(t in 1:nt){			## loop over years
    alpha.t[t] ~ dnorm(0,tau.t)		## random year effect
    Ex[t] <- mu + alpha.t[t]		## process model (does not vary with rep i)
    for(i in 1:nrep){			## loop over reps
        x[t,i] ~ dnorm(Ex[t],sigma)	## data model
    }
    px[t] ~ dnorm(Ex[t],sigma)	## predictive interval
  }
}
write.model(model=FitNormPanelRandom, con="FitNormPanelRandom.txt")

```

In the above model the “data” consists of the mosquito data, x, in a year-by-rep matrix, and the constants nt and nrep

**Lab Report Task 2**

4.  Fit the random-time model and turn in a plot like in (1) with the posterior CI and PI plotted against the data.

```{r}
init.cond3 <- function(){
  ## starts each chain from the same initial conditions
  dev_mean = rowMeans(df[,2:6])-mean(unlist(df[,2:6]))
  list(sigma=runif(n=1, min=0.001, max=10), mu=mean(unlist(df[,2:6])), alpha.t=dev_mean, tau.t = 1/var(dev_mean))
}

b3 = openbugs(data=data,  ## data passed to the model
  init=init.cond3,    ## initial conditions, NULL is equivalent to “gen inits”
	model.file="FitNormPanelRandom.txt",  ## file name of our BUGS file 
	n.chains=3,		## number of MCMC chains
	n.iter=2000,		## length of each chain
	n.burnin=100,		## burn in to exclude
	n.thin = 2,		## thin
	parameters.to.save=c("Ex","px","sigma", "alpha.t", "tau.t","mu")  ## parameters we want to track
)
quants3 <- apply(b3$sims.matrix,2, quantile, c(0.025, 0.5, 0.975))
quants3

plot(rep(1995:2004,5),unlist(data$x), ylim=c(min(quants3[,1:20]),max(quants3[,1:20])), main="Panel w/RE", xlab = "Year",ylab="Population")
lines(1995:2004, quants3[2,1:10], col=3) # median
lines(1995:2004, quants3[1,1:10], col=3, lty=2) # CI
lines(1995:2004, quants3[3,1:10], col=3, lty=2) # CI
lines(1995:2004, quants3[1,11:20], col=2, lty=2) # PI
lines(1995:2004, quants3[3,11:20], col=2, lty=2) # PI

```

5.	Based on the posterior mean estimates from this model, approximately what percentage of the variance in the mosquito densities is explained by the year effects? Which parameters (and from which models) do you need to look at to assess this?

Visually it is about half.

Mathematically I can examine the RSS in the constant-mean scenario and compare it to the RSS using the random effects ("Ex" monitor). The RSS in the constant-mean scenario is the TSS.
```{r}
n = 5
RSS_b3 = sum((as.vector(data$x)-rep(b3$median$Ex, n))^2)
RSS_b2 = sum((as.vector(data$x)-rep(b2$median$mu, n*10))^2)
1-RSS_b3/RSS_b2
```
About 65% of the variance is explained by the random effects model.

## Mixed Effects

You are discussing your research with a colleague and mention that your random effects model showed that one year, 2002, had notably lower mosquito abundance.  He suggests that the driver may be exogenous and sends you a data file, met.csv, that contains the mean annual temperature (°C), precipitation (mm/year), and relative humidity (%) for the last 15 years.
```{r}
met <- read.csv("data/met.csv", header=T)
```
 
**Lab Report Task 3:**

1.  As an exploratory analysis of this hypothesis, plot the posterior mean of your random year effect (alpha.t) versus each of the three met variables.  Turn in figures and note which variable(s) are worth exploring further.
```{r}
library(reshape)
widemet <- cbind(met, alpha.t = c(b3$mean$alpha.t, NA,NA,NA,NA,NA))
longmet <- melt(met, "year")

par(mfrow=c(1,3))
with(widemet, plot(precip, alpha.t))
with(widemet, plot(MAT, alpha.t))
with(widemet, plot(RH, alpha.t))
par(mfrow=c(1,1))

p2 <- ggplot(longmet, aes(year, value, color=variable)) + geom_line() + theme_bw()  + scale_color_brewer(type = "seq", palette = 3) +scale_y_log10()
p2

cor(widemet[1:10,2:5])
```
It appears that precipitation is correlated with the random effect.

2.	Convert the random effects model to a mixed effects model by converting the mean, mu, to a linear model, beta0 + beta1*y[i] where y is the meteorological covariate you want to include, while keeping the random year effect.  Cut-and-paste your BUGS model into your lab report.
```{r}
FitNormPanelMixed <-function(){
  beta0 ~ dnorm(0,0.001)     ## prior mean
  beta1 ~ dnorm(0,0.001)     ## prior mean
  sigma ~ dgamma(0.001,0.001)	## prior residual precision
  tau.t ~ dgamma(0.001,0.001)	## prior year-effect precision
  
  for(t in 1:nt){			## loop over years
    alpha.t[t] ~ dnorm(0,tau.t)		## random year effect
    mu[t] <- beta0 + beta1*y[t]
    Ex[t] <- mu[t] + alpha.t[t]		## process model (does not vary with rep i)
    for(i in 1:nrep){			## loop over reps
        x[t,i] ~ dnorm(Ex[t],sigma)	## data model
    }
    px[t] ~ dnorm(Ex[t],sigma)	## predictive interval
  }
}
write.model(model=FitNormPanelMixed, con="FitNormPanelMixed.txt")

init.cond4 <- function(){
  ## starts each chain from the same initial conditions
  dev_mean = rowMeans(df[,2:6])-mean(unlist(df[,2:6]))
  fit <- lm(dev_mean ~ data$y)
  list(sigma=runif(n=1, min=0.001, max=10), alpha.t=rnorm(10,0,sd(dev_mean)), tau.t = 1/var(dev_mean), beta0 =coefficients(fit)["(Intercept)"], beta1= coefficients(fit)["data$y"])
}

```

3.	Fit your mixed effects model and plot the model CI and PI vs the data

```{r}
data$y <- met[1:10,"precip"]

b4 = openbugs(data=data,  ## data passed to the model
  init=init.cond4,    ## initial conditions, NULL is equivalent to “gen inits”
  model.file="FitNormPanelMixed.txt",  ## file name of our BUGS file 
	n.chains=3,		## number of MCMC chains
	n.iter=5000,		## length of each chain
	n.burnin=1000,		## burn in to exclude
	n.thin = 2,		## thin
	parameters.to.save=c("Ex","px","sigma", "alpha.t", "tau.t","beta0","beta1")  ## parameter2s we want to track
)
quants4 <- apply(b4$sims.matrix,2, quantile, c(0.025, 0.5, 0.975))
quants4

plot(rep(1995:2004,5),unlist(data$x), ylim=c(min(quants4[,1:20]),max(quants4[,1:20])), main="Panel w/RE & Precip", xlab = "Year",ylab="Population")
lines(1995:2004, quants4[2,1:10], col=3) # median
lines(1995:2004, quants4[1,1:10], col=3, lty=2) # CI
lines(1995:2004, quants4[3,1:10], col=3, lty=2) # CI
lines(1995:2004, quants4[1,11:20], col=2, lty=2) # PI
lines(1995:2004, quants4[3,11:20], col=2, lty=2) # PI

```

4.	Create a summary table that provides the posterior parameter means and CI for all 3 models and their DIC scores.

```{r}
cols <- c(1, 3,5,7) # mean, 2.5%, 50%, 97.5%
# explicitly use data.frame version of cbind since $summary is a matrix
rbind(cbind.data.frame(b2$summary[c("mu","prec"),cols],model="b2"), cbind.data.frame(b3$summary[21:32,cols],model="b3"), cbind.data.frame(b4$summary[21:34,cols],model="b4"))

data.frame(model = c(paste0("b",2:4)),DIC = c(b2$DIC,b3$DIC,b4$DIC))
```
The model does not always appear to converge to appropriate betas. Sometimes beta converges to something similar to alpha.t ~ precip, but most of the time it does not. Placing more restrictive priors on beta and alpha appear to mitigate this issue, but do not entirely resolve it.

5.	Extra Credit: Use the best fitting model to forecast the next 5 years (2005-2009) of mosquito abundance including an uncertainty estimate (predictive interval). Turn in both a graph and table of your forecast.

```{r}
# Sum of RE and beta0 + beta1*precip
 ymean = mean(b4$mean$alpha.t) + b4$mean$beta0 + b4$mean$beta1*met$precip[11:15]

alphas <- c("alpha.t[1]", "alpha.t[2]", "alpha.t[3]", "alpha.t[4]", "alpha.t[5]", "alpha.t[6]", "alpha.t[7]", "alpha.t[8]", "alpha.t[9]", "alpha.t[10]")
data$sims.matrix <- b4$sims.matrix
data$xpred = 2005:2009
data$precip = met$precip[11:15]
# Simulate CIs and PIs


credi_predi <- function(data){
  data$npred <- length(data$xpred)
  ## storage for predictive/credible interval
  data$ypred <- matrix(0.0,nrow=dim(data$sims.matrix)[1],ncol=data$npred)	
  data$ycred <- matrix(0.0,nrow=dim(data$sims.matrix)[1],ncol=data$npred)	
  for(g in 1:dim(data$sims.matrix)[1]){
  # cover complete MCMC chain
      data$Ey <- data$sims.matrix[g,"beta0"] + data$sims.matrix[g,"beta1"] * data$precip + mean(data$sims.matrix[g,alphas]) + rnorm(data$npred, 0, sqrt(1/data$sims.matrix[g,"tau.t"]))
      data$ycred[g,] <- data$Ey
      data$ypred[g,] <- rnorm(data$npred,data$Ey,sqrt(1/data$sims.matrix[g,"sigma"]))
  }
  
  data$ci <- apply(data$ycred,2,quantile,c(0.025,0.5,0.975))  ## credible interval and median
  data$pi <- apply(data$ypred,2,quantile,c(0.025,0.5, 0.975))		## prediction interval
  return(data)
}

output <- credi_predi(data)

plot(rep(1995:2004,5),unlist(data$x), xlim=c(1995,2009),ylim=c(min(quants4[,1:20]),max(quants4[,1:20])), main="Panel w/RE & Precip", xlab = "Year",ylab="Population")
lines(1995:2009, c(quants4[2,1:10], output$ci[2,]), col=3) # median
lines(1995:2009, c(quants4[1,1:10], output$ci[1,]), col=3, lty=2) # CI
lines(1995:2009, c(quants4[3,1:10], output$ci[3,]), col=3, lty=2) # CI
lines(1995:2009, c(quants4[1,11:20], output$pi[1,]), col=2, lty=2) # PI
lines(1995:2009, c(quants4[3,11:20], output$pi[3,]), col=2, lty=2) # PI
abline(v=2004)
```
Here the CI/PI both incorporate the mean of alpha.t and tau.t, while PI also incorporates sigma.

One of the major stumbling blocks for me in this analysis is that tau.t and sigma failed to converge quickly. I put something of a very uniformative prior on them resulting in very long burn ins. The result is pretty satisfying.
